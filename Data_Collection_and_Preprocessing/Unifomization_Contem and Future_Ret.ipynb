{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import datetime as dt\n",
    "import pandas_market_calendars as mcal\n",
    "import re\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection(wrds_username = \"connorwz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SP500_CRSP_data(year_range):\n",
    "    first_year, last_year = str(year_range[0]),str(year_range[1])\n",
    "    sp_500_query = f\"\"\"SELECT a.*, b.date, b.ret, b.prc, b.openprc\n",
    "                        FROM crsp.dsp500list as a,\n",
    "                        crsp.dsf as b\n",
    "                        WHERE a.permno=b.permno\n",
    "                        and b.date >= a.start and b.date<= a.ending\n",
    "                        and b.date>='01/01/{first_year}' and b.date<='12/31/{last_year}'\n",
    "                        order by date;\"\"\"\n",
    "    sp_500 = db.raw_sql(sp_500_query,date_cols=['start', 'ending', 'date'])\n",
    "    dse = db.raw_sql(\"\"\"\n",
    "                        select comnam,ncusip, namedt, nameendt,permno\n",
    "                        from crsp.dsenames\n",
    "                        \"\"\", date_cols=['namedt', 'nameendt'])\n",
    "    dse['nameendt']=dse['nameendt'].fillna(pd.to_datetime('today'))\n",
    "    sp500_full = pd.merge(sp_500, dse, how = 'left', on = 'permno')\n",
    "    sp500_full = sp500_full.loc[(sp500_full.date>=sp500_full.namedt) \\\n",
    "                                & (sp500_full.date<=sp500_full.nameendt)]\n",
    "    sp500_full.reset_index(inplace = True,drop = True)\n",
    "    sp500_full = sp500_full[[\"permno\",\"date\",\"comnam\",\"ret\",\"openprc\",\"prc\"]]\n",
    "    sp500_full[\"prc\"] = sp500_full[\"prc\"].apply(abs)\n",
    "    sp500_full[\"CO_ret\"] = (sp500_full['prc'] - sp500_full['openprc'])/sp500_full['openprc']\n",
    "    return sp500_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>rp_entity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10104</td>\n",
       "      <td>D6489C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10107</td>\n",
       "      <td>228D42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10138</td>\n",
       "      <td>2F94A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10145</td>\n",
       "      <td>FF6644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10516</td>\n",
       "      <td>2B7A40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno rp_entity_id\n",
       "0   10104       D6489C\n",
       "1   10107       228D42\n",
       "2   10138       2F94A5\n",
       "3   10145       FF6644\n",
       "4   10516       2B7A40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_file = pd.read_csv(\"SP500_Mapping_file.csv\")\n",
    "SP500_entity_id_str = ','.join(f\"'{id}'\" for id in list(mapping_file.rp_entity_id)) \n",
    "mapping_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SP500_RP_headline_data(year_range):\n",
    "    years = range(int(year_range[0]),int(year_range[-1])+1)\n",
    "    years_str = [str(year) for year in years]\n",
    "    RP_df = pd.DataFrame()\n",
    "    for year in years_str:\n",
    "        RP_year_query =f\"\"\"\n",
    "                        SELECT DISTINCT timestamp_utc,rp_entity_id,headline,css\n",
    "                        FROM rpna.rpa_djpr_equities_{year}\n",
    "                        WHERE rp_entity_id IN ({SP500_entity_id_str})\n",
    "                        \"\"\"\n",
    "        RP_df = pd.concat((RP_df,db.raw_sql(RP_year_query)),axis = 0)\n",
    "    RP_df = RP_df.drop_duplicates((\"rp_entity_id\",\"headline\"))\n",
    "    return RP_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contem_ret(year_range):\n",
    "    first_year,last_year = int(year_range[0]),int(year_range[-1])\n",
    "\n",
    "    # Create financial dataframe from crsp and link to entity id\n",
    "    sp500_crsp = SP500_CRSP_data(year_range)\n",
    "    sp500_crsp_rpid =  sp500_crsp.merge(mapping_file, on = \"permno\", how = \"inner\")\n",
    "\n",
    "    # Create RavenPack headline data and map the timestamp to contemporaneous return date\n",
    "    sp500_rp =  SP500_RP_headline_data(year_range)\n",
    "    sp500_rp.set_index(\"timestamp_utc\",inplace= True)\n",
    "    sp500_rp[\"timestamp_NY\"] = pd.to_datetime(sp500_rp.index).tz_localize(\"UTC\").tz_convert(\"America/New_York\")\n",
    "    sp500_rp = sp500_rp.reset_index()\n",
    "    sp500_rp['index'] = sp500_rp.index\n",
    "    nyse = mcal.get_calendar(\"NYSE\")\n",
    "    nyse_tradingdays= nyse.valid_days(start_date=f\"{str(first_year)}-01-01\",end_date=f\"{str(last_year)}-12-31\")\\\n",
    "        .tz_localize(None).tz_localize(\"America/New_York\")\n",
    "    nyse_tradingdays_closing = nyse_tradingdays + dt.timedelta(hours = 16)\n",
    "    trading_days_df = pd.DataFrame({'trading_close': nyse_tradingdays_closing, 'contem_ret_date': nyse_tradingdays_closing.date})\n",
    "\n",
    "    # Use merge_asof to align the headlines with the trading close times\n",
    "    sp500_rp = pd.merge_asof(sp500_rp.sort_values('timestamp_NY'), trading_days_df,\n",
    "                            left_on='timestamp_NY', right_on='trading_close',\n",
    "                            direction='forward')\n",
    "    sp500_rp = sp500_rp.sort_values(\"index\")\n",
    "    sp500_rp\n",
    "    sp500_rp = sp500_rp[['timestamp_utc', 'rp_entity_id', 'headline', 'css', 'timestamp_NY', 'contem_ret_date']]\n",
    "    sp500_rp = sp500_rp.reset_index()\n",
    "    sp500_rp.drop(columns = [\"index\"],inplace = True)\n",
    "\n",
    "    # Merge crsp dataframe with RP dataframe\n",
    "    sp500_rp_contem_ret = sp500_rp[[\"contem_ret_date\",\"rp_entity_id\",\"headline\", \"css\"]]\n",
    "    sp500_rp_contem_ret = sp500_rp_contem_ret.dropna()\n",
    "    sp500_rp_contem_ret.contem_ret_date = pd.to_datetime(sp500_rp_contem_ret.contem_ret_date)\n",
    "    sp500_crsp_rpid = sp500_crsp_rpid[[\"date\",\"rp_entity_id\",\"comnam\",\"ret\"]]\n",
    "    sp500_crsp_rp_contem_ret = pd.merge(sp500_crsp_rpid,sp500_rp_contem_ret,left_on=[\"date\",\"rp_entity_id\"],\\\n",
    "                                        right_on=[\"contem_ret_date\",\"rp_entity_id\"],how = \"inner\").drop(columns = \"contem_ret_date\")\n",
    "    \n",
    "    # sp500_crsp_rp_contem_ret.drop_duplicates((\"rp_entity_id\",\"headline\"),inplace=True)\n",
    "    sp500_crsp_rp_contem_ret.dropna(inplace=True)\n",
    "    return sp500_crsp_rp_contem_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_ret(year_range):\n",
    "    first_year,last_year = int(year_range[0]),int(year_range[-1])\n",
    "\n",
    "    # Create financial dataframe from crsp and link to entity id\n",
    "    sp500_crsp = SP500_CRSP_data(year_range)\n",
    "    sp500_crsp_rpid =  sp500_crsp.merge(mapping_file, on = \"permno\", how = \"inner\")\n",
    "\n",
    "    # Create RavenPack headline data and map the timestamp to future return date\n",
    "    sp500_rp =  SP500_RP_headline_data(year_range)\n",
    "    sp500_rp.set_index(\"timestamp_utc\",inplace= True)\n",
    "    sp500_rp[\"timestamp_NY\"] = pd.to_datetime(sp500_rp.index).tz_localize(\"UTC\").tz_convert(\"America/New_York\")\n",
    "    nyse = mcal.get_calendar(\"NYSE\")\n",
    "    nyse_tradingdays= nyse.valid_days(start_date=f\"{str(first_year)}-01-01\",end_date=f\"{str(last_year)}-12-31\")\\\n",
    "        .tz_localize(None).tz_localize(\"America/New_York\")\n",
    "    nyse_tradingdays_opening = nyse_tradingdays + dt.timedelta(hours = 9)\n",
    "    nyse_tradingdays_closing = nyse_tradingdays + dt.timedelta(hours = 16)\n",
    "    def future_ret_date(timestamp):\n",
    "        later_opening = nyse_tradingdays_opening[nyse_tradingdays_opening>=timestamp]\n",
    "        later_closing = nyse_tradingdays_closing[nyse_tradingdays_closing>=timestamp]\n",
    "        if (not later_opening.empty) & (not later_closing.empty):\n",
    "            next_opening = later_opening[0]\n",
    "            next_closing = later_closing[0]\n",
    "            if next_opening.date() == next_closing.date():\n",
    "                return [next_opening.date(),1]\n",
    "            else: \n",
    "                return [next_opening.date(),0]\n",
    "        else:\n",
    "            return [None,None]\n",
    "    sp500_rp_future_ret_date = sp500_rp.apply(lambda row:future_ret_date(row['timestamp_NY']),axis = 1, result_type=\"expand\")\n",
    "    sp500_rp_future_ret_date = sp500_rp_future_ret_date.rename(columns = {0:\"future_ret_date\",1:\"bool_CO_ret\"}) \n",
    "    sp500_rp = pd.concat([sp500_rp,sp500_rp_future_ret_date],axis = 1)\n",
    "\n",
    "    # Merge crsp dataframe with RP dataframe\n",
    "    sp500_rp.future_ret_date = pd.to_datetime(sp500_rp.future_ret_date)\n",
    "    sp500_crsp_rp_future_ret = sp500_crsp_rpid.merge(sp500_rp,left_on=[\"date\",\"rp_entity_id\"],right_on = [\"future_ret_date\",\"rp_entity_id\"],how = \"inner\")\n",
    "    sp500_crsp_rp_future_ret = sp500_crsp_rp_future_ret[[\"date\",\"rp_entity_id\",\"comnam\",\"CO_ret\",\"ret\",\"headline\",\"bool_CO_ret\", \"css\"]]\n",
    "    \n",
    "    sp500_crsp_rp_future_ret = sp500_crsp_rp_future_ret.drop_duplicates(subset = [\"rp_entity_id\",\"headline\"])\n",
    "    sp500_crsp_rp_future_ret[\"future_ret\"] = sp500_crsp_rp_future_ret.apply(lambda row: row[\"CO_ret\"] if row[\"bool_CO_ret\"] \\\n",
    "                                                                            else (row[\"ret\"] if not row[\"bool_CO_ret\"]  else None), axis = 1)\n",
    "    sp500_crsp_rp_future_ret = sp500_crsp_rp_future_ret.drop(columns = ['CO_ret','ret','bool_CO_ret'])\n",
    "    # sp500_crsp_rp_future_ret.drop_duplicates(inplace = True)\n",
    "    sp500_crsp_rp_future_ret.dropna(inplace = True)\n",
    "    \n",
    "    return sp500_crsp_rp_future_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove individual commenter first\n",
    "def remove_individual(headline):\n",
    "    by_pattern = re.search(r\" (-+)? By\", headline, flags = re.IGNORECASE)\n",
    "    if by_pattern:\n",
    "        return headline[:by_pattern.start()]\n",
    "    else:\n",
    "        return headline\n",
    "    \n",
    "# Tokenize the headline into tokens which are alphanumeric words including period . \n",
    "def custom_tokenizer(headline):\n",
    "    tokens = re.findall(r\"\\b[a-zA-z0-9\\.][a-zA-z0-9\\.]+\\b\",headline.lower())  \n",
    "    return tokens\n",
    "\n",
    "# Remove tokens according to the principles \n",
    "def custom_processor(headline, remove_words):\n",
    "    tokens = custom_tokenizer(headline)\n",
    "    new_tokens = [token for token in tokens if token not in remove_words]\n",
    "    return \" \".join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_heandline(df):\n",
    "    df[\"vocab_con_headline\"] = df.headline.apply(remove_individual)\n",
    "    vocab_con_headlines = df.vocab_con_headline.tolist()\n",
    "    vocab = collections.Counter()\n",
    "\n",
    "    # Create a vocab dictionary with the words and their counts\n",
    "    for headline in vocab_con_headlines:\n",
    "        vocab.update(custom_tokenizer(headline))\n",
    "    remove_words = list(ENGLISH_STOP_WORDS)\n",
    "    words_once = [word for word,count in vocab.items() if count ==1]\n",
    "    top_100_count = sorted(vocab.values(),reverse = True)[99]\n",
    "    words_top_100 = [word for word,count in vocab.items() if count >=top_100_count]\n",
    "    remove_words.extend(words_once)\n",
    "    remove_words.extend(words_top_100)\n",
    "    remove_words = set(remove_words)\n",
    "\n",
    "    df.vocab_con_headline = df.vocab_con_headline.apply(lambda headline: custom_processor(headline, remove_words))\n",
    "    df_cleaned = df.dropna(subset=['vocab_con_headline'])\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2020,2021):\n",
    "    data_type = \"contem\"\n",
    "    year_range = (i, i)\n",
    "    if data_type == \"contem\":\n",
    "        df = contem_ret(year_range)\n",
    "    else:\n",
    "        df = future_ret(year_range)\n",
    "\n",
    "    df_cleaned = clean_heandline(df)\n",
    "    print(df_cleaned)\n",
    "    df_cleaned.to_csv(\"/shared/share_tm-finance/Processed_df_Sentiment/One_year_window/{data}_{year}.csv\".format(data = data_type, year = i))\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

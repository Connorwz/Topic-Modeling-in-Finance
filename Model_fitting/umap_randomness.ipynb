{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.cluster import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import gc\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "def uh(min_cluster_size):\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    umap_model = UMAP(n_components = 10,random_state=42)\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size,metric = \"euclidean\", cluster_selection_method=\"eom\",\n",
    "                            gen_min_span_tree = True, prediction_data = False, min_samples = 40)\n",
    "    vectorizer_model = CountVectorizer()\n",
    "    Topic_model = BERTopic(embedding_model=embedding_model, umap_model=umap_model, hdbscan_model=hdbscan_model, vectorizer_model=vectorizer_model,\n",
    "                        calculate_probabilities = False,verbose = True)\n",
    "    return Topic_model\n",
    "\n",
    "def tr_te_split(headlines,df,embeddings,k=1):\n",
    "    indices = np.arange(len(headlines))\n",
    "    tr_ind, te_ind = train_test_split(indices, test_size=0.2, shuffle= True, random_state=k)\n",
    "    tr_df = df.iloc[tr_ind,:]\n",
    "    te_df = df.iloc[te_ind,:]\n",
    "    tr_headlines = [headlines[ind] for ind in tr_ind]\n",
    "    te_headlines = [headlines[ind] for ind in te_ind]\n",
    "    tr_embeddings = embeddings[tr_ind,:]\n",
    "    return tr_df,te_df,tr_headlines,te_headlines,tr_embeddings\n",
    "\n",
    "def find_min_cluster_size(min_cluster_size,min_cluster_size_list,headlines,embeddings,target_num_cluster):\n",
    "    Topic_model = uh(min_cluster_size)\n",
    "    Topic_model.fit(headlines,embeddings)\n",
    "    num_cluster = Topic_model.get_topic_info().shape[0]-1\n",
    "    if num_cluster > (target_num_cluster + round(5*target_num_cluster/120)) or num_cluster < (target_num_cluster - round(5*target_num_cluster/120)):\n",
    "        no_tuning = 0\n",
    "        tried_min_cluster_size_list = []\n",
    "    while (num_cluster > (target_num_cluster + round(5*target_num_cluster/120)) or num_cluster < (target_num_cluster - round(5*target_num_cluster/120))) and (min_cluster_size not in tried_min_cluster_size_list):\n",
    "        no_tuning +=1\n",
    "        tried_min_cluster_size_list.append(min_cluster_size)\n",
    "        if num_cluster > (target_num_cluster + round(5*target_num_cluster/120)):\n",
    "            if np.array(min_cluster_size_list)[np.array(min_cluster_size_list) > min_cluster_size].size >0:\n",
    "                min_cluster_size = np.array(min_cluster_size_list)[np.array(min_cluster_size_list) > min_cluster_size][0]\n",
    "                Topic_model = uh(min_cluster_size)\n",
    "                Topic_model.fit(headlines,embeddings)\n",
    "                num_cluster = Topic_model.get_topic_info().shape[0]-1\n",
    "            else:\n",
    "                print(f\"after {no_tuning-1}th tuning, the final min_cluster_size is {min_cluster_size}\")\n",
    "                return min_cluster_size\n",
    "        else:\n",
    "            if np.array(min_cluster_size_list)[np.array(min_cluster_size_list) < min_cluster_size].size > 0:\n",
    "                min_cluster_size = np.array(min_cluster_size_list)[np.array(min_cluster_size_list) < min_cluster_size][-1]\n",
    "                Topic_model = uh(min_cluster_size)\n",
    "                Topic_model.fit(headlines,embeddings)\n",
    "                num_cluster = Topic_model.get_topic_info().shape[0]-1\n",
    "            else:\n",
    "                print(f\"after {no_tuning-1}th tuning, the final min_cluster_size is {min_cluster_size}\")\n",
    "                return min_cluster_size\n",
    "        print(f\"after {no_tuning}th tuning, the min_cluster_size is {min_cluster_size}\")\n",
    "    return min_cluster_size\n",
    "\n",
    "def linear_regression(tr_topic_dist,te_topic_dist,tr_df,te_df):\n",
    "    tr_ret_topic_dist = pd.concat([tr_df.drop(columns = [\"rp_entity_id\",\"headline\",\"vocab_con_headline\",\"css\"]),pd.DataFrame(tr_topic_dist)],axis = 1)\n",
    "    tr_grouped = tr_ret_topic_dist.groupby(['date',\"comnam\",\"ret\"])\n",
    "    tr_grouped_sum = tr_grouped.sum()\n",
    "    tr_X = np.array(tr_grouped_sum)\n",
    "    tr_ret = [ind[2] for ind in list(tr_grouped_sum.index)]\n",
    "    tr_Y = np.array(tr_ret).reshape(-1,1)\n",
    "    tr_Y_mean = np.mean(tr_Y)\n",
    "    regression = LinearRegression(fit_intercept=True)\n",
    "    regression.fit(tr_X,tr_Y)\n",
    "    tr_r2 = regression.score(tr_X,tr_Y)\n",
    "\n",
    "    te_ret_topic_dist = pd.concat([te_df.drop(columns = [\"rp_entity_id\",\"headline\",\"vocab_con_headline\",\"css\"]),pd.DataFrame(te_topic_dist)],axis = 1)\n",
    "    te_grouped = te_ret_topic_dist.groupby(['date',\"comnam\",\"ret\"])\n",
    "    te_grouped_sum = te_grouped.sum()\n",
    "    te_X = np.array(te_grouped_sum)\n",
    "    te_ret = [ind[2] for ind in list(te_grouped_sum.index)]\n",
    "    te_Y = np.array(te_ret).reshape(-1,1)\n",
    "    te_Y_pred = regression.predict(te_X)\n",
    "    te_sst = np.sum((te_Y-tr_Y_mean)**2)\n",
    "    te_sse = np.sum((te_Y-te_Y_pred)**2)\n",
    "    te_r2 = 1-te_sse/te_sst\n",
    "    return tr_r2,te_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-computations finished\n",
      "computation for 2014 starts\n",
      "The df and embeddings in 2014 finished\n",
      "pos_cluster_num in 2014 is: 43\n",
      "neg_cluster_num in 2014 is: 18\n",
      "neu_cluster_num in 2014 is: 59\n",
      "The 1th computation in 2014 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 11:33:45,463 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:33:49,189 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:33:49,193 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:33:53,473 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:33:53,490 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:33:54,243 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:33:54,550 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:33:55,328 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:33:55,330 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:33:57,152 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:33:57,160 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:33:57,377 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:33:57,506 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:34:04,232 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:34:04,238 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:34:11,015 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:34:11,036 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:34:11,719 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real pos num_cluster is 55\n",
      "real neg num_cluster is 25\n",
      "real neu num_cluster is 59\n",
      "The final number of clusters in 2014 is 139\n",
      "Model fitting for 1th computation in 2014 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:03<00:00, 25.78it/s]\n",
      "100%|██████████| 37/37 [00:01<00:00, 31.31it/s]\n",
      "100%|██████████| 132/132 [00:04<00:00, 31.54it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 23.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 47.05it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations for 1th computation in 2014 finished\n",
      "The 2th computation in 2014 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 11:34:26,495 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:34:30,238 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:34:30,242 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:34:33,920 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:34:33,936 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:34:34,471 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:34:34,513 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:34:38,417 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:34:38,420 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:34:41,151 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:34:41,157 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:34:41,333 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:34:41,385 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:34:47,547 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:34:47,552 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:34:54,941 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:34:54,960 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:34:55,589 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real pos num_cluster is 2\n",
      "real neg num_cluster is 3\n",
      "real neu num_cluster is 59\n",
      "The final number of clusters in 2014 is 64\n",
      "Model fitting for 2th computation in 2014 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:03<00:00, 31.83it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 47.03it/s]\n",
      "100%|██████████| 132/132 [00:04<00:00, 28.73it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 33.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.88it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations for 2th computation in 2014 finished\n",
      "The 3th computation in 2014 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 11:35:09,111 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:35:12,773 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:35:12,776 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:35:17,010 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:35:17,027 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:35:17,628 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:35:17,853 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:35:18,589 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:35:18,591 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:35:20,566 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:35:20,576 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:35:20,787 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:35:20,844 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:35:27,481 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:35:27,487 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:35:33,816 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:35:33,839 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:35:34,504 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real pos num_cluster is 54\n",
      "real neg num_cluster is 2\n",
      "real neu num_cluster is 58\n",
      "The final number of clusters in 2014 is 114\n",
      "Model fitting for 3th computation in 2014 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:03<00:00, 25.23it/s]\n",
      "100%|██████████| 37/37 [00:01<00:00, 36.72it/s]\n",
      "100%|██████████| 132/132 [00:04<00:00, 29.40it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 44.17it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 25.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations for 3th computation in 2014 finished\n",
      "The 4th computation in 2014 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 11:35:49,872 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:35:53,530 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:35:53,534 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:35:57,195 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:35:57,212 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:35:57,716 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:35:57,903 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:35:58,804 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:35:58,806 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:36:01,543 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:36:01,550 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:36:01,730 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:36:01,784 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:36:08,034 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:36:08,039 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:36:15,015 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:36:15,035 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:36:15,692 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real pos num_cluster is 56\n",
      "real neg num_cluster is 3\n",
      "real neu num_cluster is 58\n",
      "The final number of clusters in 2014 is 117\n",
      "Model fitting for 4th computation in 2014 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:03<00:00, 28.07it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 47.27it/s]\n",
      "100%|██████████| 132/132 [00:04<00:00, 31.41it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 23.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 49.65it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 35.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations for 4th computation in 2014 finished\n",
      "The 5th computation in 2014 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 11:36:30,513 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:36:34,206 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:36:34,210 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:36:37,496 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:36:37,510 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:36:38,004 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:36:38,170 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:36:38,933 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:36:38,935 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:36:40,473 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:36:40,480 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:36:40,655 - BERTopic - Representation - Completed ✓\n",
      "2024-09-30 11:36:40,720 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-09-30 11:36:47,329 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-09-30 11:36:47,333 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-09-30 11:36:52,971 - BERTopic - Cluster - Completed ✓\n",
      "2024-09-30 11:36:52,992 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-09-30 11:36:53,654 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real pos num_cluster is 41\n",
      "real neg num_cluster is 6\n",
      "real neu num_cluster is 58\n",
      "The final number of clusters in 2014 is 105\n",
      "Model fitting for 5th computation in 2014 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:03<00:00, 28.69it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 46.22it/s]\n",
      "100%|██████████| 132/132 [00:04<00:00, 31.38it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 24.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 49.51it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations for 5th computation in 2014 finished\n",
      "comutation for 2014 ends\n"
     ]
    }
   ],
   "source": [
    "df_folder = \"/shared/share_tm-finance/Final/Processed_df/One_year_window\"\n",
    "embeddings_folder = \"/shared/share_tm-finance/Final/Embeddings/One_year_window\"\n",
    "\n",
    "year_list = range(2014,2015)\n",
    "num_clusters = 120\n",
    "\n",
    "com_tr_r2_dict = dict()\n",
    "com_te_r2_dict = dict()\n",
    "mean_com_tr_r2_dict = dict()\n",
    "mean_com_te_r2_dict = dict()\n",
    "sep_tr_r2_dict = dict()\n",
    "sep_te_r2_dict = dict()\n",
    "mean_sep_tr_r2_dict = dict()\n",
    "mean_sep_te_r2_dict = dict()\n",
    "num_clusters_dict = dict()\n",
    "mean_num_clusters_dict = dict()\n",
    "\n",
    "print(\"pre-computations finished\")\n",
    "\n",
    "for year in year_list:\n",
    "    print(f\"computation for {year} starts\")\n",
    "    df = pd.read_csv(df_folder+f\"/contem_{year}.csv\")\n",
    "    headlines = df.vocab_con_headline.tolist()\n",
    "    embeddings = np.load(embeddings_folder+f\"/contem_{year}_embeddings.npy\")\n",
    "\n",
    "    print(f\"The df and embeddings in {year} finished\")\n",
    "\n",
    "    pos_indices = df[df['css'] > 0].index\n",
    "    neg_indices = df[df['css'] < 0].index\n",
    "    neu_indices = df[df['css'] == 0].index\n",
    "    pos_df = df.iloc[pos_indices,:]\n",
    "    neg_df = df.iloc[neg_indices,:]\n",
    "    neu_df = df.iloc[neu_indices,:]\n",
    "    pos_headlines = [headlines[ind] for ind in pos_indices]\n",
    "    neg_headlines = [headlines[ind] for ind in neg_indices]\n",
    "    neu_headlines = [headlines[ind] for ind in neu_indices]\n",
    "    pos_embeddings = embeddings[pos_indices,:]\n",
    "    neg_embeddings = embeddings[neg_indices,:]\n",
    "    neu_embeddings = embeddings[neu_indices,:]\n",
    "\n",
    "    #set pos_cluster_num, neg_cluster_num, neu_cluster_num based on the number of embeddings\n",
    "    pos_cluster_num = int(num_clusters * len(pos_embeddings) / len(embeddings))\n",
    "    neg_cluster_num = int(num_clusters * len(neg_embeddings) / len(embeddings))\n",
    "    neu_cluster_num = int(num_clusters * len(neu_embeddings) / len(embeddings))\n",
    "    diff = num_clusters - (pos_cluster_num + neg_cluster_num + neu_cluster_num)\n",
    "    if pos_cluster_num < neg_cluster_num and pos_cluster_num < neu_cluster_num:\n",
    "        pos_cluster_num += diff\n",
    "    elif neg_cluster_num < pos_cluster_num and neg_cluster_num < neu_cluster_num:\n",
    "        neg_cluster_num += diff\n",
    "    else:\n",
    "        neu_cluster_num += diff\n",
    "\n",
    "    print(f\"pos_cluster_num in {year} is:\", pos_cluster_num)\n",
    "    print(f\"neg_cluster_num in {year} is:\", neg_cluster_num)\n",
    "    print(f\"neu_cluster_num in {year} is:\", neu_cluster_num)\n",
    "\n",
    "    \n",
    "    pos_min_cluster_size,neg_min_cluster_size,neu_min_cluster_size = 205,200,200\n",
    "    pos_tr_df, pos_te_df, pos_tr_headlines,pos_te_headlines,pos_tr_embeddings = tr_te_split(pos_headlines,pos_df,pos_embeddings)\n",
    "    neg_tr_df, neg_te_df, neg_tr_headlines,neg_te_headlines,neg_tr_embeddings = tr_te_split(neg_headlines,neg_df,neg_embeddings)\n",
    "    neu_tr_df, neu_te_df, neu_tr_headlines,neu_te_headlines,neu_tr_embeddings = tr_te_split(neu_headlines,neu_df,neu_embeddings)\n",
    "    pos_tr_df.reset_index(drop=True,inplace=True)\n",
    "    pos_te_df.reset_index(drop=True,inplace=True)\n",
    "    neg_tr_df.reset_index(drop=True,inplace=True)\n",
    "    neg_te_df.reset_index(drop=True,inplace=True)\n",
    "    neu_tr_df.reset_index(drop=True,inplace=True)\n",
    "    neu_te_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    com_tr_r2_list = []\n",
    "    com_te_r2_list = []\n",
    "    sep_tr_r2_list = []\n",
    "    sep_te_r2_list = []\n",
    "    num_clusters_list = []\n",
    "\n",
    "    for i in range(1,6):\n",
    "        print(f\"The {i}th computation in {year} starts\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        pos_topic_model = uh(pos_min_cluster_size)\n",
    "        neg_topic_model = uh(neg_min_cluster_size)\n",
    "        neu_topic_model = uh(neu_min_cluster_size)\n",
    "        pos_topic_model.fit(pos_tr_headlines,pos_tr_embeddings)\n",
    "        neg_topic_model.fit(neg_tr_headlines,neg_tr_embeddings)\n",
    "        neu_topic_model.fit(neu_tr_headlines,neu_tr_embeddings)\n",
    "        print(f\"real pos num_cluster is {pos_topic_model.get_topic_info().shape[0]-1}\")\n",
    "        print(f\"real neg num_cluster is {neg_topic_model.get_topic_info().shape[0]-1}\")\n",
    "        print(f\"real neu num_cluster is {neu_topic_model.get_topic_info().shape[0]-1}\")\n",
    "        num_clusters = pos_topic_model.get_topic_info().shape[0]+neg_topic_model.get_topic_info().shape[0]+neu_topic_model.get_topic_info().shape[0]-3\n",
    "        print(f\"The final number of clusters in {year} is {num_clusters}\")\n",
    "        num_clusters_list.append(num_clusters)\n",
    "        print(F\"Model fitting for {i}th computation in {year} finished\")\n",
    "\n",
    "        pos_tr_topic_dist, _ = pos_topic_model.approximate_distribution(pos_tr_headlines)\n",
    "        neg_tr_topic_dist, _ = neg_topic_model.approximate_distribution(neg_tr_headlines)\n",
    "        neu_tr_topic_dist, _ = neu_topic_model.approximate_distribution(neu_tr_headlines)\n",
    "        pos_te_topic_dist, _ = pos_topic_model.approximate_distribution(pos_te_headlines)\n",
    "        neg_te_topic_dist, _ = neg_topic_model.approximate_distribution(neg_te_headlines)\n",
    "        neu_te_topic_dist, _ = neu_topic_model.approximate_distribution(neu_te_headlines)\n",
    "        \n",
    "        # This is separate version of R square\n",
    "        pos_tr_r2, pos_te_r2 = linear_regression(pos_tr_topic_dist,pos_te_topic_dist,pos_tr_df,pos_te_df)\n",
    "        neg_tr_r2, neg_te_r2 = linear_regression(neg_tr_topic_dist,neg_te_topic_dist,neg_tr_df,neg_te_df)\n",
    "        neu_tr_r2, neu_te_r2 = linear_regression(neu_tr_topic_dist,neu_te_topic_dist,neu_tr_df,neu_te_df)\n",
    "        sep_tr_r2 = (pos_tr_r2* len(pos_embeddings) / len(embeddings)) + (neg_tr_r2* len(neg_embeddings) / len(embeddings)) + (neu_tr_r2* len(neu_embeddings) / len(embeddings))\n",
    "        sep_tr_r2_list.append(sep_tr_r2)\n",
    "        sep_te_r2 = (pos_te_r2* len(pos_embeddings) / len(embeddings)) + (neg_te_r2* len(neg_embeddings) / len(embeddings)) + (neu_te_r2* len(neu_embeddings) / len(embeddings))\n",
    "        sep_te_r2_list.append(sep_te_r2)\n",
    "\n",
    "        # This is combine version of R square\n",
    "        combined_tr_df = pd.concat([pos_tr_df,neg_tr_df,neu_tr_df],axis = 0)\n",
    "        combined_tr_df.reset_index(drop=True,inplace=True)\n",
    "        combined_tr_topic_dist = block_diag(pos_tr_topic_dist,neg_tr_topic_dist,neu_tr_topic_dist)\n",
    "        combined_te_df = pd.concat([pos_te_df,neg_te_df,neu_te_df],axis = 0)\n",
    "        combined_te_df.reset_index(drop=True,inplace=True)\n",
    "        combined_te_topic_dist = block_diag(pos_te_topic_dist,neg_te_topic_dist,neu_te_topic_dist)\n",
    "        com_tr_r2, com_te_r2 = linear_regression(combined_tr_topic_dist,combined_te_topic_dist,combined_tr_df,combined_te_df)\n",
    "        com_tr_r2_list.append(com_tr_r2)\n",
    "        com_te_r2_list.append(com_te_r2)\n",
    "\n",
    "        print(F\"Computations for {i}th computation in {year} finished\")\n",
    "\n",
    "    num_clusters_dict[year] = num_clusters_list\n",
    "    mean_num_clusters_dict[year] = np.mean(num_clusters_list)\n",
    "    \n",
    "    mean_sep_tr_r2 = np.mean(sep_tr_r2_list)\n",
    "    mean_sep_te_r2 = np.mean(sep_te_r2_list)\n",
    "    sep_tr_r2_dict[year] = sep_tr_r2_list\n",
    "    sep_te_r2_dict[year] = sep_te_r2_list\n",
    "    mean_sep_tr_r2_dict[year] = mean_sep_tr_r2\n",
    "    mean_sep_te_r2_dict[year] = mean_sep_te_r2\n",
    "\n",
    "    mean_com_tr_r2 = np.mean(com_tr_r2_list)\n",
    "    mean_com_te_r2 = np.mean(com_te_r2_list)\n",
    "    com_tr_r2_dict[year] = com_tr_r2_list\n",
    "    com_te_r2_dict[year] = com_te_r2_list\n",
    "    mean_com_tr_r2_dict[year] = mean_com_tr_r2\n",
    "    mean_com_te_r2_dict[year] = mean_com_te_r2\n",
    "    print(f\"comutation for {year} ends\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of clusters is {2014: [139, 64, 114, 117, 105]}\n",
      "The mean number of clusters is {2014: 107.8}\n",
      "The insample R square of combined version is {2014: [0.052501885010649785, 0.007803406859818063, 0.017249533375712667, 0.019380744659257765, 0.018269602424957898]}\n",
      "The outsample R square of combined version is {2014: [0.027192164060876545, 0.0047592867115535675, 0.011239337100404256, 0.01249582103625213, 0.011557966121010343]}\n",
      "The mean insample R square of combined version is {2014: 0.023041034466079236}\n",
      "THe mean outsample R square of combined version is {2014: 0.013448915006019368}\n",
      "The insample R square of separate version is {2014: [0.016757433799557842, 0.0028091665926831344, 0.006618498285481221, 0.007340049541884292, 0.006741373074125069]}\n",
      "The outsample R square of separate version is {2014: [0.010016055131618162, 0.0012623930462520795, 0.0038650026114559724, 0.004572299403354408, 0.004039114019756721]}\n",
      "The mean insample R square of separate version is {2014: 0.008053304258746312}\n",
      "The mean outsample R square of separate version is {2014: 0.004750972842487469}\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of clusters is {num_clusters_dict}\")\n",
    "print(f\"The mean number of clusters is {mean_num_clusters_dict}\")\n",
    "print(f\"The insample R square of combined version is {com_tr_r2_dict}\")\n",
    "print(f\"The outsample R square of combined version is {com_te_r2_dict}\")\n",
    "print(f\"The mean insample R square of combined version is {mean_com_tr_r2_dict}\")\n",
    "print(f\"THe mean outsample R square of combined version is {mean_com_te_r2_dict}\")\n",
    "print(f\"The insample R square of separate version is {sep_tr_r2_dict}\")\n",
    "print(f\"The outsample R square of separate version is {sep_te_r2_dict}\")\n",
    "print(f\"The mean insample R square of separate version is {mean_sep_tr_r2_dict}\")\n",
    "print(f\"The mean outsample R square of separate version is {mean_sep_te_r2_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
